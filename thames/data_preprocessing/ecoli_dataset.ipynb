{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "961ea9293ce3da23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ecoli Thames Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685ba7537b5bf89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T13:24:40.971849Z",
     "start_time": "2023-11-06T13:24:39.020496Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import bng_latlon as bl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34c204f55899cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Specify the path(s) to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T15:21:13.977878Z",
     "start_time": "2023-11-06T15:21:13.973478Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir_new_samples_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/Reader Output\"\n",
    "dir_store_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/temporary results\"\n",
    "filename_new_samples = \"merged_data.csv\"\n",
    "# file_old_samples_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/SafeCREW/Thames Ecoli/historical_samples.csv\"\n",
    "file_old_samples_path = None\n",
    "\n",
    "# paths to further features\n",
    "manual_counting_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/further_features/Thames Sampling Ecoli - manual counting.xlsx\"\n",
    "water_quality_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/further_features/Thames Sampling Water Quality Data.xlsx\"\n",
    "historic_discharges_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/further_features/Thames Water Historic Discharges by site (missing fleet main before 2023).xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(dir_new_samples_path):\n",
    "    raise ValueError(\n",
    "        \"The path to the folder containing the new samples excel files is not a directory\"\n",
    "    )\n",
    "\n",
    "if not os.path.isdir(dir_store_path):\n",
    "    raise ValueError(\n",
    "        \"The path to store the concatenated excel file is not a directory\"\n",
    "    )\n",
    "\n",
    "if file_old_samples_path is not None:\n",
    "    if not os.path.isfile(file_old_samples_path):\n",
    "        raise ValueError(\n",
    "            \"The path to the file containing the old samples excel file is not a file\"\n",
    "        )\n",
    "\n",
    "if not filename_new_samples.endswith(\".csv\"):\n",
    "    raise ValueError(\"The name of the new file must include the csv extension\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genericpath import isdir\n",
    "\n",
    "\n",
    "def append_data(new_data_folder, old_dataset_path):\n",
    "    \"\"\"\n",
    "    Append the data in the new_data_folder to the old_dataset\n",
    "    \"\"\"\n",
    "\n",
    "    new_samples = []\n",
    "    for root, dirs, files in os.walk(new_data_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                new_samples.append(pd.read_excel(os.path.join(root, file)))\n",
    "            elif file.endswith(\".csv\"):\n",
    "                new_samples.append(pd.read_csv(os.path.join(root, file)))\n",
    "            elif file.endswith(\".DS_Store\"):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(\"The file extension is not supported\")\n",
    "\n",
    "        for dir in dirs:\n",
    "            if isdir(os.path.join(root, dir)):\n",
    "                new_samples.append(\n",
    "                    append_data(os.path.join(root, dir), old_dataset_path)\n",
    "                )\n",
    "\n",
    "    new_samples_df = pd.concat(new_samples, ignore_index=True)\n",
    "    if old_dataset_path is not None:\n",
    "        if old_dataset_path.endswith(\".xlsx\"):\n",
    "            old_samples_df = pd.read_excel(old_dataset_path)\n",
    "        elif old_dataset_path.endswith(\".csv\"):\n",
    "            old_samples_df = pd.read_csv(old_dataset_path)\n",
    "        else:\n",
    "            raise ValueError(\"The file extension is not supported\")\n",
    "        new_samples_df = pd.concat(\n",
    "            [old_samples_df, new_samples_df], ignore_index=True\n",
    "        )\n",
    "    return new_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reader_output_df = append_data(dir_new_samples_path, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reader_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reader_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_manual_counting_df = pd.read_excel(manual_counting_path)\n",
    "raw_water_quality_df = pd.read_excel(water_quality_path)\n",
    "raw_historic_discharges_df = pd.read_excel(\n",
    "    historic_discharges_path, header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_manual_counting_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_water_quality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_historic_discharges_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Automated Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_output_df = raw_reader_output_df.copy()\n",
    "\n",
    "reader_output_df.drop_duplicates(inplace=True)\n",
    "\n",
    "reader_output_df[[\"Date\", \"Time\", \"SiteSample\"]] = raw_reader_output_df[\n",
    "    \"Sample ID\"\n",
    "].str.split(\"_\", expand=True)\n",
    "\n",
    "reader_output_df[\"Date\"] = pd.to_datetime(\n",
    "    reader_output_df[\"Date\"], format=\"%Y%m%d\"\n",
    ").dt.date\n",
    "reader_output_df[\"Time\"].replace(\"XXXX\", pd.NaT, inplace=True)  # type: ignore\n",
    "reader_output_df[\"Time\"] = pd.to_datetime(\n",
    "    reader_output_df[\"Time\"], format=\"%H%M\", errors=\"coerce\"\n",
    ").dt.strftime(\"%H:%M\")\n",
    "reader_output_df[\"Image Date Time\"] = pd.to_datetime(\n",
    "    reader_output_df[\"Image Date Time\"]\n",
    ")\n",
    "\n",
    "date_col = reader_output_df.pop(\"Date\")\n",
    "time_col = reader_output_df.pop(\"Time\")\n",
    "\n",
    "reader_output_df.insert(2, \"Date\", date_col)\n",
    "reader_output_df.insert(3, \"Time\", time_col)\n",
    "\n",
    "reader_output_df.insert(4, \"Site\", reader_output_df[\"SiteSample\"].str.extract(\"([A-Za-z]+)\", expand=True))  # type: ignore\n",
    "reader_output_df.insert(5, \"Sample\", reader_output_df[\"SiteSample\"].str.extract(\"([\\d.]+)\", expand=True))  # type: ignore\n",
    "\n",
    "reader_output_df.drop(columns=[\"SiteSample\"], inplace=True)\n",
    "reader_output_df.drop(columns=[\"Sample ID\"], inplace=True)\n",
    "\n",
    "reader_output_df.drop(columns=[\"Barcode Text\", \"Plate Type\"], inplace=True)\n",
    "\n",
    "# drop useless columns\n",
    "reader_output_df.drop(\n",
    "    columns=[\n",
    "        \"Red With Gas Raw Count\",\n",
    "        \"Red With Gas Edited Count\",\n",
    "        \"Red Without Gas Raw Count\",\n",
    "        \"Red Without Gas Edited Count\",\n",
    "        \"Red Without Gas Calculated Result\",\n",
    "        \"Blue With Gas Raw Count\",\n",
    "        \"Blue With Gas Edited Count\",\n",
    "        \"Blue Without Gas Raw Count\",\n",
    "        \"Blue Without Gas Edited Count\",\n",
    "        \"Blue Without Gas Calculated Result\",\n",
    "        \"Comments\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "reader_output_df.rename(\n",
    "    {\n",
    "        \"Red With Gas Calculated Result\": \"Coliform (1ml)\",\n",
    "        \"Blue With Gas Calculated Result\": \"Ecoli (1ml)\",\n",
    "    },\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "reader_output_df[\"Sample\"] = reader_output_df[\"Sample\"].astype(float)\n",
    "reader_output_df[\"Site\"] = reader_output_df[\"Site\"].str.upper()\n",
    "\n",
    "reader_output_df.dropna(subset=[\"Coliform (1ml)\", \"Ecoli (1ml)\"], inplace=True)\n",
    "\n",
    "\n",
    "reader_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_extra_data_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/2023_08_10_AM_pt2.csv\"\n",
    "raw_extra_data_df = pd.read_csv(raw_extra_data_path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_data_df = raw_extra_data_df.copy()\n",
    "\n",
    "extra_data_df.drop_duplicates(inplace=True)\n",
    "\n",
    "extra_data_df[[\"Date\", \"Time\", \"SiteSample\"]] = raw_extra_data_df[\n",
    "    \"Sample ID\"\n",
    "].str.split(\"_\", expand=True)\n",
    "\n",
    "extra_data_df[\"Date\"] = pd.to_datetime(\n",
    "    extra_data_df[\"Date\"], format=\"%Y%m%d\"\n",
    ").dt.date\n",
    "extra_data_df[\"Time\"].replace(\"XXXX\", pd.NaT, inplace=True)  # type: ignore\n",
    "extra_data_df[\"Time\"] = pd.to_datetime(\n",
    "    extra_data_df[\"Time\"], format=\"%H%M\", errors=\"coerce\"\n",
    ").dt.strftime(\"%H:%M\")\n",
    "extra_data_df[\"Image Date Time\"] = pd.to_datetime(\n",
    "    extra_data_df[\"Image Date Time\"]\n",
    ")\n",
    "\n",
    "date_col = extra_data_df.pop(\"Date\")\n",
    "time_col = extra_data_df.pop(\"Time\")\n",
    "\n",
    "extra_data_df.insert(2, \"Date\", date_col)\n",
    "extra_data_df.insert(3, \"Time\", time_col)\n",
    "\n",
    "extra_data_df.insert(4, \"Site\", extra_data_df[\"SiteSample\"].str.extract(\"([A-Za-z]+)\", expand=True))  # type: ignore\n",
    "extra_data_df.insert(5, \"Sample\", extra_data_df[\"SiteSample\"].str.extract(\"([\\d.]+)\", expand=True))  # type: ignore\n",
    "\n",
    "extra_data_df.drop(columns=[\"SiteSample\"], inplace=True)\n",
    "extra_data_df.drop(columns=[\"Sample ID\"], inplace=True)\n",
    "extra_data_df.drop(columns=[\"Plate Type\"], inplace=True)\n",
    "\n",
    "extra_data_df[\"Sample\"] = extra_data_df[\"Sample\"].astype(float)\n",
    "extra_data_df[\"Site\"] = extra_data_df[\"Site\"].str.upper()\n",
    "\n",
    "extra_data_df.dropna(subset=[\"Coliform (1ml)\", \"Ecoli (1ml)\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_output_df = pd.concat([reader_output_df, extra_data_df], ignore_index=True)\n",
    "reader_output_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Manual Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_counting_df = raw_manual_counting_df.copy()\n",
    "\n",
    "manual_counting_df.drop_duplicates(inplace=True)\n",
    "\n",
    "manual_counting_df[\"Sample\"] = manual_counting_df[\"Sample\"].astype(float)\n",
    "manual_counting_df.rename(\n",
    "    {\"Counter\": \"Technician\"},\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "manual_counting_df[\"Date\"] = manual_counting_df[\"Date\"].dt.date\n",
    "manual_counting_df[\"Time\"] = pd.to_datetime(\n",
    "    manual_counting_df[\"Time\"], format=\"%H:%M:%S\", errors=\"coerce\"\n",
    ").dt.strftime(\"%H:%M\")\n",
    "\n",
    "manual_counting_df.dropna(\n",
    "    subset=[\"Coliform (1ml)\", \"Ecoli (1ml)\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_counting_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Water Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_quality_df = raw_water_quality_df.copy()\n",
    "\n",
    "water_quality_df[\"Sample\"] = water_quality_df[\"Sample\"].astype(float)\n",
    "water_quality_df.rename(\n",
    "    {\"Sampler\": \"Technician\"},\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "water_quality_df = water_quality_df[water_quality_df[\"FOLLOW UP\"] != \"X\"]\n",
    "water_quality_df[\"Date\"] = water_quality_df[\"Date\"].dt.date\n",
    "water_quality_df[\"Time\"] = pd.to_datetime(\n",
    "    water_quality_df[\"Time\"], format=\"%H:%M:%S\", errors=\"coerce\"\n",
    ").dt.strftime(\"%H:%M\")\n",
    "\n",
    "water_quality_df.drop(columns=[\"FOLLOW UP\"], inplace=True)\n",
    "water_quality_df.dropna(\n",
    "    subset=[\"Temp C\", \"Ph\", \"Cond (ms)\"], inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_quality_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_manual_df = pd.concat(\n",
    "    [reader_output_df, manual_counting_df], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(\n",
    "    reader_manual_df,\n",
    "    water_quality_df,\n",
    "    how=\"outer\",\n",
    "    on=[\"Technician\", \"Date\", \"Time\", \"Site\", \"Sample\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"Coliform (1ml)\"].replace(to_replace=\"TNTC\", value=250, inplace=True)\n",
    "full_df[\"Ecoli (1ml)\"].replace(to_replace=\"TNTC\", value=250, inplace=True)\n",
    "\n",
    "full_df[\"Technician\"].replace(to_replace=\", \", value=\" - \", inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(os.path.join(dir_store_path, \"full_dataset.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_overflow_sites_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/sites/all_overflows.csv\"\n",
    "nearest_overflow_sites_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/sites/nearest_overflows.csv\"\n",
    "sampling_sites_path = \"/Users/massimilianoarca/Library/CloudStorage/OneDrive-PolitecnicodiMilano/Thames Ecoli/sites/sampling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_overflow_sites_df = pd.read_csv(all_overflow_sites_path)\n",
    "nearest_overflow_sites_df = pd.read_csv(nearest_overflow_sites_path)\n",
    "sampling_sites_df = pd.read_csv(sampling_sites_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = full_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"Coliform (1ml)\"] = final_df[\"Coliform (1ml)\"].astype(float)\n",
    "final_df[\"Ecoli (1ml)\"] = final_df[\"Ecoli (1ml)\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.groupby([\"Technician\", \"Date\", \"Time\", \"Site\", \"Sample\"], as_index=False).agg(\n",
    "    {\n",
    "        'Coliform (1ml)': [\"mean\", \"std\"],\n",
    "        'Ecoli (1ml)': [\"mean\", \"std\"],\n",
    "        'Temp C': [\"mean\", \"std\"],\n",
    "        'Ph': [\"mean\", \"std\"],\n",
    "        'Cond (ms)': [\"mean\", \"std\"],\n",
    "    }\n",
    "    ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
